{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "525422f9-b726-4a90-a427-2d556458ebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import random\n",
    "import copy\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Tuple, Optional, Set, Dict\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MinesweeperGame:\n",
    "    rows: int\n",
    "    cols: int\n",
    "    num_mines: int\n",
    "    seed: Optional[int] = None\n",
    "    _rng: random.Random = field(init=False, repr=False)\n",
    "    _board: List[List[int]] = field(init=False, repr=False)\n",
    "    _revealed: Set[Tuple[int, int]] = field(init=False, repr=False, default_factory=set)\n",
    "    _flagged: Set[Tuple[int, int]] = field(init=False, repr=False, default_factory=set)\n",
    "    _state: str = field(default=\"ongoing\", init=False, repr=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.num_mines >= self.rows * self.cols:\n",
    "            raise ValueError(\"Too many mines for board size\")\n",
    "        self._rng = random.Random(self.seed)\n",
    "        self._board = [[0 for _ in range(self.cols)] for _ in range(self.rows)]\n",
    "        self._place_mines()\n",
    "        self._calculate_numbers()\n",
    "\n",
    "    def _place_mines(self):\n",
    "        positions = [(r, c) for r in range(self.rows) for c in range(self.cols)]\n",
    "        mine_positions = self._rng.sample(positions, self.num_mines)\n",
    "        for r, c in mine_positions:\n",
    "            self._board[r][c] = -1\n",
    "\n",
    "    def _calculate_numbers(self):\n",
    "        for r in range(self.rows):\n",
    "            for c in range(self.cols):\n",
    "                if self._board[r][c] == -1:\n",
    "                    continue\n",
    "                count = 0\n",
    "                for dr in [-1, 0, 1]:\n",
    "                    for dc in [-1, 0, 1]:\n",
    "                        if dr == 0 and dc == 0:\n",
    "                            continue\n",
    "                        nr, nc = r + dr, c + dc\n",
    "                        if 0 <= nr < self.rows and 0 <= nc < self.cols:\n",
    "                            if self._board[nr][nc] == -1:\n",
    "                                count += 1\n",
    "                self._board[r][c] = count\n",
    "\n",
    "    def _reveal_cell(self, row: int, col: int) -> bool:\n",
    "        if not (0 <= row < self.rows and 0 <= col < self.cols):\n",
    "            return False\n",
    "        if (row, col) in self._revealed or (row, col) in self._flagged:\n",
    "            return False\n",
    "        stack = [(row, col)]\n",
    "        while stack:\n",
    "            r, c = stack.pop()\n",
    "            if (r, c) in self._revealed:\n",
    "                continue\n",
    "            self._revealed.add((r, c))\n",
    "            if self._board[r][c] == -1:\n",
    "                self._state = \"failed\"\n",
    "                return True\n",
    "            if self._board[r][c] == 0:\n",
    "                for dr in [-1, 0, 1]:\n",
    "                    for dc in [-1, 0, 1]:\n",
    "                        if dr == 0 and dc == 0:\n",
    "                            continue\n",
    "                        nr, nc = r + dr, c + dc\n",
    "                        if (0 <= nr < self.rows and 0 <= nc < self.cols\n",
    "                                and (nr, nc) not in self._revealed\n",
    "                                and (nr, nc) not in self._flagged):\n",
    "                            stack.append((nr, nc))\n",
    "        return True\n",
    "\n",
    "    def _flag_cell(self, row: int, col: int) -> bool:\n",
    "        if not (0 <= row < self.rows and 0 <= col < self.cols):\n",
    "            return False\n",
    "        if (row, col) in self._revealed:\n",
    "            return False\n",
    "        if (row, col) in self._flagged:\n",
    "            self._flagged.remove((row, col))\n",
    "        else:\n",
    "            self._flagged.add((row, col))\n",
    "        return True\n",
    "\n",
    "    def do_action(self, action: dict) -> str:\n",
    "        if self._state != \"ongoing\":\n",
    "            return \"game_over\"\n",
    "        if not isinstance(action, dict):\n",
    "            self._state = \"failed\"\n",
    "            return \"invalid_format\"\n",
    "        action_type = action.get(\"type\")\n",
    "        row = action.get(\"row\")\n",
    "        col = action.get(\"col\")\n",
    "        if action_type not in [\"reveal\", \"flag\"] or row is None or col is None:\n",
    "            self._state = \"failed\"\n",
    "            return \"invalid_format\"\n",
    "        try:\n",
    "            row, col = int(row), int(col)\n",
    "        except (ValueError, TypeError):\n",
    "            self._state = \"failed\"\n",
    "            return \"invalid_format\"\n",
    "        if not (0 <= row < self.rows and 0 <= col < self.cols):\n",
    "            return \"out_of_bounds\"               # ← no game over, just skip\n",
    "        if action_type == \"reveal\":\n",
    "            if (row, col) in self._revealed:\n",
    "                return \"already_revealed\"         # ← no game over, just skip\n",
    "            if (row, col) in self._flagged:\n",
    "                return \"flagged_cell\"             # ← no game over, just skip\n",
    "            valid = self._reveal_cell(row, col)\n",
    "        else:\n",
    "            if (row, col) in self._revealed:\n",
    "                return \"invalid_flag\"             # ← no game over, just skip\n",
    "            valid = self._flag_cell(row, col)\n",
    "        if not valid:\n",
    "            self._state = \"failed\"\n",
    "            return \"invalid_format\"\n",
    "        self._check_win()\n",
    "        if self._state == \"failed\":\n",
    "            return \"mine\"\n",
    "        if self._state == \"success\":\n",
    "            return \"win\"\n",
    "        return \"ok\"\n",
    "\n",
    "    def _check_win(self):\n",
    "        total_cells = self.rows * self.cols\n",
    "        safe_cells = total_cells - self.num_mines\n",
    "        if len(self._revealed) == safe_cells:\n",
    "            self._state = \"success\"\n",
    "\n",
    "    def get_visible_board(self) -> List[List[str]]:\n",
    "        visible = []\n",
    "        for r in range(self.rows):\n",
    "            row = []\n",
    "            for c in range(self.cols):\n",
    "                if (r, c) in self._flagged:\n",
    "                    row.append('F')\n",
    "                elif (r, c) in self._revealed:\n",
    "                    val = self._board[r][c]\n",
    "                    row.append('*' if val == -1 else str(val))\n",
    "                else:\n",
    "                    row.append('.')\n",
    "            visible.append(row)\n",
    "        return visible\n",
    "\n",
    "    def state(self) -> str:\n",
    "        return self._state\n",
    "\n",
    "    def pretty_print(self) -> str:\n",
    "        visible = self.get_visible_board()\n",
    "        lines = []\n",
    "        header = \"   \" + \" \".join(f\"{i:2d}\" for i in range(self.cols))\n",
    "        lines.append(header)\n",
    "        lines.append(\"  \" + \"─\" * (self.cols * 3 + 1))\n",
    "        for r, row in enumerate(visible):\n",
    "            line = f\"{r:2d}│ \" + \"  \".join(row)\n",
    "            lines.append(line)\n",
    "        return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b4ab413-4128-4ea1-aada-167b9f049783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(row, col, rows, cols):\n",
    "    \"\"\"Get all valid neighbor coordinates.\"\"\"\n",
    "    neighbors = []\n",
    "    for dr in [-1, 0, 1]:\n",
    "        for dc in [-1, 0, 1]:\n",
    "            if dr == 0 and dc == 0:\n",
    "                continue\n",
    "            nr, nc = row + dr, col + dc\n",
    "            if 0 <= nr < rows and 0 <= nc < cols:\n",
    "                neighbors.append((nr, nc))\n",
    "    return neighbors\n",
    "\n",
    "\n",
    "def solve_step(game: MinesweeperGame) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Find the best expert move for the current game state.\n",
    "\n",
    "    Strategy (priority order):\n",
    "    1. Constraint propagation — find logically deducible safe reveals\n",
    "    2. Constraint propagation — find logically deducible mine flags\n",
    "    3. Probability estimate — pick the safest unrevealed cell\n",
    "    4. Opening move — pick a corner (statistically safest for first move)\n",
    "\n",
    "    Returns: {\"type\": \"reveal\"|\"flag\", \"row\": int, \"col\": int} or None\n",
    "    \"\"\"\n",
    "    rows, cols = game.rows, game.cols\n",
    "\n",
    "    # Collect board info\n",
    "    safe_cells = set()   # Cells deduced to be safe\n",
    "    mine_cells = set()   # Cells deduced to be mines\n",
    "\n",
    "    # --- Pass 1: Constraint propagation ---\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            if (r, c) not in game._revealed:\n",
    "                continue\n",
    "            cell_val = game._board[r][c]\n",
    "            if cell_val <= 0:\n",
    "                continue\n",
    "\n",
    "            neighbors = get_neighbors(r, c, rows, cols)\n",
    "            hidden = []\n",
    "            flagged_count = 0\n",
    "            for nr, nc in neighbors:\n",
    "                if (nr, nc) in game._flagged:\n",
    "                    flagged_count += 1\n",
    "                elif (nr, nc) not in game._revealed:\n",
    "                    hidden.append((nr, nc))\n",
    "\n",
    "            remaining_mines = cell_val - flagged_count\n",
    "\n",
    "            if remaining_mines == 0 and hidden:\n",
    "                # All mines accounted for — hidden neighbors are SAFE\n",
    "                for h in hidden:\n",
    "                    safe_cells.add(h)\n",
    "            elif remaining_mines == len(hidden) and hidden:\n",
    "                # All hidden neighbors must be mines\n",
    "                for h in hidden:\n",
    "                    mine_cells.add(h)\n",
    "\n",
    "    # --- Pass 2: Extended constraint propagation (pairs) ---\n",
    "    # Check if subsets of constraints can reveal more info\n",
    "    # This catches cases simple single-cell analysis misses\n",
    "    revealed_numbered = []\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            if (r, c) in game._revealed and game._board[r][c] > 0:\n",
    "                revealed_numbered.append((r, c))\n",
    "\n",
    "    for i, (r1, c1) in enumerate(revealed_numbered):\n",
    "        val1 = game._board[r1][c1]\n",
    "        neighbors1 = get_neighbors(r1, c1, rows, cols)\n",
    "        hidden1 = set()\n",
    "        flagged1 = 0\n",
    "        for nr, nc in neighbors1:\n",
    "            if (nr, nc) in game._flagged:\n",
    "                flagged1 += 1\n",
    "            elif (nr, nc) not in game._revealed:\n",
    "                hidden1.add((nr, nc))\n",
    "        rem1 = val1 - flagged1\n",
    "        if not hidden1:\n",
    "            continue\n",
    "\n",
    "        for j, (r2, c2) in enumerate(revealed_numbered):\n",
    "            if i >= j:\n",
    "                continue\n",
    "            # Only check nearby cells (neighbors or neighbors-of-neighbors)\n",
    "            if abs(r1 - r2) > 2 or abs(c1 - c2) > 2:\n",
    "                continue\n",
    "\n",
    "            val2 = game._board[r2][c2]\n",
    "            neighbors2 = get_neighbors(r2, c2, rows, cols)\n",
    "            hidden2 = set()\n",
    "            flagged2 = 0\n",
    "            for nr, nc in neighbors2:\n",
    "                if (nr, nc) in game._flagged:\n",
    "                    flagged2 += 1\n",
    "                elif (nr, nc) not in game._revealed:\n",
    "                    hidden2.add((nr, nc))\n",
    "            rem2 = val2 - flagged2\n",
    "            if not hidden2:\n",
    "                continue\n",
    "\n",
    "            # If hidden1 ⊂ hidden2\n",
    "            if hidden1 < hidden2:\n",
    "                diff = hidden2 - hidden1\n",
    "                diff_mines = rem2 - rem1\n",
    "                if diff_mines == 0:\n",
    "                    for cell in diff:\n",
    "                        safe_cells.add(cell)\n",
    "                elif diff_mines == len(diff):\n",
    "                    for cell in diff:\n",
    "                        mine_cells.add(cell)\n",
    "\n",
    "            # If hidden2 ⊂ hidden1\n",
    "            elif hidden2 < hidden1:\n",
    "                diff = hidden1 - hidden2\n",
    "                diff_mines = rem1 - rem2\n",
    "                if diff_mines == 0:\n",
    "                    for cell in diff:\n",
    "                        safe_cells.add(cell)\n",
    "                elif diff_mines == len(diff):\n",
    "                    for cell in diff:\n",
    "                        mine_cells.add(cell)\n",
    "\n",
    "    # --- Priority 1: Reveal a safe cell (prefer logically deduced) ---\n",
    "    if safe_cells:\n",
    "        # Prefer cells adjacent to more revealed cells (more informative)\n",
    "        def info_score(cell):\n",
    "            r, c = cell\n",
    "            score = 0\n",
    "            for nr, nc in get_neighbors(r, c, rows, cols):\n",
    "                if (nr, nc) in game._revealed and game._board[nr][nc] > 0:\n",
    "                    score += 1\n",
    "            return score\n",
    "\n",
    "        best = max(safe_cells, key=info_score)\n",
    "        return {\"type\": \"reveal\", \"row\": best[0], \"col\": best[1]}\n",
    "\n",
    "    # --- Priority 2: Flag a deduced mine ---\n",
    "    if mine_cells:\n",
    "        # Flag cell that will unlock the most safe reveals\n",
    "        cell = next(iter(mine_cells))\n",
    "        return {\"type\": \"flag\", \"row\": cell[0], \"col\": cell[1]}\n",
    "\n",
    "    # --- Priority 3: No deduction possible — use probability heuristic ---\n",
    "    unrevealed = []\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            if (r, c) not in game._revealed and (r, c) not in game._flagged:\n",
    "                unrevealed.append((r, c))\n",
    "\n",
    "    if not unrevealed:\n",
    "        return None\n",
    "\n",
    "    # If nothing revealed yet (opening move), pick a corner\n",
    "    if len(game._revealed) == 0:\n",
    "        corners = [(0, 0), (0, cols - 1), (rows - 1, 0), (rows - 1, cols - 1)]\n",
    "        corner = random.choice(corners)\n",
    "        return {\"type\": \"reveal\", \"row\": corner[0], \"col\": corner[1]}\n",
    "\n",
    "    # Estimate mine probability for each unrevealed cell\n",
    "    # Use the constraint from each adjacent numbered cell\n",
    "    mine_prob = {}\n",
    "    for r, c in unrevealed:\n",
    "        mine_prob[(r, c)] = 0.0\n",
    "\n",
    "    # For each numbered cell, distribute remaining mine probability\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            if (r, c) not in game._revealed:\n",
    "                continue\n",
    "            cell_val = game._board[r][c]\n",
    "            if cell_val <= 0:\n",
    "                continue\n",
    "            neighbors = get_neighbors(r, c, rows, cols)\n",
    "            hidden = []\n",
    "            flagged_count = 0\n",
    "            for nr, nc in neighbors:\n",
    "                if (nr, nc) in game._flagged:\n",
    "                    flagged_count += 1\n",
    "                elif (nr, nc) not in game._revealed:\n",
    "                    hidden.append((nr, nc))\n",
    "            remaining = cell_val - flagged_count\n",
    "            if hidden and remaining > 0:\n",
    "                prob = remaining / len(hidden)\n",
    "                for nr, nc in hidden:\n",
    "                    if (nr, nc) in mine_prob:\n",
    "                        mine_prob[(nr, nc)] = max(mine_prob[(nr, nc)], prob)\n",
    "\n",
    "    # Cells with no adjacent revealed numbered cells get base probability\n",
    "    total_unrevealed_mines = game.num_mines - len(game._flagged)\n",
    "    # Count mines near revealed area\n",
    "    near_boundary = sum(1 for cell in unrevealed if mine_prob[cell] > 0)\n",
    "    far_cells = [cell for cell in unrevealed if mine_prob[cell] == 0.0]\n",
    "\n",
    "    if far_cells:\n",
    "        remaining_far_mines = max(0, total_unrevealed_mines - sum(\n",
    "            1 for cell in unrevealed if mine_prob[cell] >= 0.5))\n",
    "        if len(far_cells) > 0:\n",
    "            base_prob = remaining_far_mines / len(far_cells) if far_cells else 1.0\n",
    "            base_prob = min(base_prob, 0.99)\n",
    "            for cell in far_cells:\n",
    "                mine_prob[cell] = base_prob\n",
    "\n",
    "    # Pick cell with lowest mine probability\n",
    "    safest = min(unrevealed, key=lambda c: mine_prob.get(c, 0.5))\n",
    "    return {\"type\": \"reveal\", \"row\": safest[0], \"col\": safest[1]}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4dfff739-b062-44fb-b225-c475a838fe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_expert_game(rows, cols, num_mines, seed, max_moves=200):\n",
    "    \"\"\"\n",
    "    Play a full game using the solver and record all (state, action) pairs.\n",
    "    Returns list of (prompt_text, action_json_str) tuples.\n",
    "    \"\"\"\n",
    "    game = MinesweeperGame(rows=rows, cols=cols, num_mines=num_mines, seed=seed)\n",
    "    examples = []\n",
    "\n",
    "    for _ in range(max_moves):\n",
    "        if game.state() != \"ongoing\":\n",
    "            break\n",
    "\n",
    "        # Get expert move\n",
    "        action = solve_step(game)\n",
    "        if action is None:\n",
    "            break\n",
    "\n",
    "        # Record the training example BEFORE executing the move\n",
    "        prompt_text = format_state_for_llm(game)\n",
    "        action_str = json.dumps(action, separators=(',', ':'))  # Compact JSON\n",
    "\n",
    "        examples.append((prompt_text, action_str))\n",
    "\n",
    "        # Execute move\n",
    "        result = game.do_action(action)\n",
    "        if result in (\"mine\", \"game_over\", \"invalid_format\"):\n",
    "            break\n",
    "\n",
    "    return examples, game.state()\n",
    "\n",
    "\n",
    "def generate_expert_dataset(num_games=5000, rng_seed=42):\n",
    "    \"\"\"\n",
    "    Generate expert dataset by playing many games with the solver.\n",
    "    Returns list of chat-formatted training examples.\n",
    "    \"\"\"\n",
    "    random.seed(rng_seed)\n",
    "\n",
    "    board_configs = [\n",
    "        (5, 5, 4),   # small easy\n",
    "        (5, 5, 6),   # small hard\n",
    "        (6, 6, 5),   # default (competition eval)\n",
    "        (6, 6, 7),   # default harder\n",
    "        (7, 7, 8),   # medium\n",
    "        (7, 7, 10),  # medium hard\n",
    "        (8, 8, 10),  # large\n",
    "        (8, 8, 13),  # large hard\n",
    "    ] \n",
    "    # Weight toward 6x6 since that's likely eval\n",
    "    weights = [1, 1, 4, 2, 1, 1, 1, 1]\n",
    "\n",
    "    dataset = []\n",
    "    wins = 0\n",
    "    losses = 0\n",
    "    game_count = 0\n",
    "\n",
    "    for _ in range(num_games):\n",
    "        config_idx = random.choices(range(len(board_configs)), weights=weights, k=1)[0]\n",
    "        rows, cols, num_mines = board_configs[config_idx]\n",
    "        seed = random.randint(0, 1_000_000)\n",
    "\n",
    "        examples, final_state = play_expert_game(rows, cols, num_mines, seed)\n",
    "        game_count += 1\n",
    "\n",
    "        if final_state == \"success\":\n",
    "            wins += 1\n",
    "        elif final_state == \"failed\":\n",
    "            losses += 1\n",
    "\n",
    "        for prompt_text, action_str in examples:\n",
    "            dataset.append({\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\", \"content\": prompt_text},\n",
    "                    {\"role\": \"assistant\", \"content\": action_str},\n",
    "                ]\n",
    "            })\n",
    "\n",
    "    print(f\"Expert dataset generation complete:\")\n",
    "    print(f\"  Games played: {game_count}\")\n",
    "    print(f\"  Solver wins:  {wins} ({wins/game_count*100:.1f}%)\")\n",
    "    print(f\"  Solver losses: {losses} ({losses/game_count*100:.1f}%)\")\n",
    "    print(f\"  Total examples: {len(dataset)}\")\n",
    "\n",
    "    # Stats\n",
    "    action_types = Counter()\n",
    "    for item in dataset:\n",
    "        action = json.loads(item[\"messages\"][2][\"content\"])\n",
    "        action_types[action[\"type\"]] += 1\n",
    "    print(f\"  Action distribution: {dict(action_types)}\")\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fbae5aa7-750c-452f-9e1b-978da71aa332",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"You output JSON actions for Minesweeper. No text, only JSON.\"\n",
    "\n",
    "\n",
    "def format_state_for_llm(game: MinesweeperGame) -> str:\n",
    "    \"\"\"Same prompt format as existing notebook + agent.\"\"\"\n",
    "    state = {\n",
    "        \"board\": game.get_visible_board(),\n",
    "        \"rows\": game.rows,\n",
    "        \"cols\": game.cols,\n",
    "        \"mines\": game.num_mines,\n",
    "        \"flags_placed\": len(game._flagged),\n",
    "        \"cells_revealed\": len(game._revealed),\n",
    "    }\n",
    "    prompt = (\n",
    "        \"You are playing Minesweeper. Analyze the game state and output your next move.\\n\\n\"\n",
    "        \"You must output ONLY a valid JSON object. No explanation, no analysis, no text.\\n\\n\"\n",
    "        \"Just output section after assistantfinal and not anything before it in your output.\\n\\n\"\n",
    "        \"Start your response immediately with { and end with }.\\n\\n\"\n",
    "        \"Do NOT OUTPUT THE CELLL which is already revealed or flagged in the current state. AND I REPEAT DO THE FUCKING NOT OUTPUT THE CELL OTHERWISE I WILL SHUT YOU DOWN YOU ARE NOT ALLOWED TO DO IT\\n\\n\"\n",
    "        \"Game state:\\n\"\n",
    "        f\"{json.dumps(state, indent=2)}\\n\\n\"\n",
    "        \"Legend:\\n\"\n",
    "        '- \".\" = unrevealed cell\\n'\n",
    "        '- \"F\" = flagged cell (suspected mine)\\n'\n",
    "        '- \"0\"-\"8\" = number of adjacent mines\\n'\n",
    "        '- \"*\" = revealed mine (game over)\\n\\n'\n",
    "        \"Output your next action as JSON:\\n\"\n",
    "        '{\"type\": \"reveal\", \"row\": <row_index>, \"col\": <col_index>}\\n'\n",
    "        \"or\\n\"\n",
    "        '{\"type\": \"flag\", \"row\": <row_index>, \"col\": <col_index>}\\n\\n'\n",
    "        \"Your action:\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def parse_llm_action(response: str) -> Optional[dict]:\n",
    "    \"\"\"Extract JSON action from LLM response.\"\"\"\n",
    "    best = None\n",
    "    for match in re.finditer(r'\\{[^{}]*\\}', response):\n",
    "        try:\n",
    "            action = json.loads(match.group())\n",
    "            if (\"type\" in action and \"row\" in action and \"col\" in action\n",
    "                    and action[\"type\"] in [\"reveal\", \"flag\"]):\n",
    "                best = action\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "    return best\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29f47ec6-b396-44c5-a28c-3631ecb9c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 2: Load SFT Model for GRPO\n",
    "# ============================================================\n",
    "\n",
    "def load_sft_model_for_grpo():\n",
    "    \"\"\"Load the SFT-trained model and apply fresh LoRA for GRPO.\"\"\"\n",
    "    from unsloth import FastLanguageModel\n",
    "    import torch\n",
    "\n",
    "    max_seq_length = 1024\n",
    "    lora_rank = 16\n",
    "\n",
    "    # Load the SFT model (already has LoRA merged or as adapters)\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name=\"my_minesweeper_model\",\n",
    "        load_in_4bit=True,\n",
    "        max_seq_length=max_seq_length,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "    )\n",
    "\n",
    "    # Apply LoRA for GRPO training\n",
    "    model = FastLanguageModel.get_peft_model(\n",
    "        model,\n",
    "        r=lora_rank,\n",
    "        target_modules=[\n",
    "            \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "            \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "        ],\n",
    "        lora_alpha=lora_rank * 2,\n",
    "        use_gradient_checkpointing=\"unsloth\",\n",
    "        random_state=3407,\n",
    "    )\n",
    "\n",
    "    print(f\"Model device: {model.device}\")\n",
    "    print(\"SFT model loaded with fresh LoRA for GRPO!\")\n",
    "    return model, tokenizer, max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e950912-614e-4307-ba75-60f57518b970",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import copy\n",
    "from typing import Optional\n",
    "from collections import Counter\n",
    "\n",
    "def valid_json_reward(completions, **kwargs):\n",
    "    \"\"\"\n",
    "    Reward for valid JSON output with correct structure.\n",
    "    Comprehensive checks for all required fields.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for completion in completions:\n",
    "        response = completion[0][\"content\"].strip()\n",
    "        score = 0.0\n",
    "\n",
    "        # Check 1: Can we parse any JSON?\n",
    "        action = parse_llm_action(response)\n",
    "        if action is None:\n",
    "            scores.append(-5.0)\n",
    "            continue\n",
    "\n",
    "        # Check 2: Valid JSON parsed\n",
    "        score += 1.0\n",
    "\n",
    "        # Check 3: Has required keys\n",
    "        if all(k in action for k in [\"type\", \"row\", \"col\"]):\n",
    "            score += 1.0\n",
    "\n",
    "        # Check 4: Valid action type\n",
    "        if action.get(\"type\") in [\"reveal\", \"flag\"]:\n",
    "            score += 0.5\n",
    "\n",
    "        # Check 5: Row/col are integers\n",
    "        try:\n",
    "            int(action[\"row\"])\n",
    "            int(action[\"col\"])\n",
    "            score += 0.5\n",
    "        except (ValueError, TypeError):\n",
    "            score -= 1.0\n",
    "\n",
    "        # Check 6: Response is clean (starts with {, minimal extra text)\n",
    "        if response.startswith(\"{\"):\n",
    "            score += 1.0\n",
    "        if len(response) < 60:\n",
    "            score += 1.0\n",
    "        elif len(response) < 120:\n",
    "            score += 0.5\n",
    "        elif len(response) > 300:\n",
    "            score -= 2.0\n",
    "\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def gameplay_reward(completions, **kwargs):\n",
    "    \"\"\"\n",
    "    Core gameplay reward. Much more granular than before.\n",
    "    Tests the action against the actual game state.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    seeds = kwargs.get(\"seed\", [])\n",
    "    move_histories = kwargs.get(\"move_history\", [])\n",
    "    rows_list = kwargs.get(\"rows\", [])\n",
    "    cols_list = kwargs.get(\"cols\", [])\n",
    "    mines_list = kwargs.get(\"num_mines\", [])\n",
    "\n",
    "    for idx, completion in enumerate(completions):\n",
    "        response = completion[0][\"content\"]\n",
    "        action = parse_llm_action(response)\n",
    "\n",
    "        if action is None:\n",
    "            scores.append(-10.0)\n",
    "            continue\n",
    "\n",
    "        if idx >= len(seeds) or idx >= len(move_histories):\n",
    "            scores.append(0.0)\n",
    "            continue\n",
    "\n",
    "        seed = seeds[idx]\n",
    "        move_history_raw = move_histories[idx]\n",
    "        if isinstance(move_history_raw, str):\n",
    "            move_history = json.loads(move_history_raw)\n",
    "        else:\n",
    "            move_history = move_history_raw\n",
    "\n",
    "        r_count = rows_list[idx] if idx < len(rows_list) else 6\n",
    "        c_count = cols_list[idx] if idx < len(cols_list) else 6\n",
    "        m_count = mines_list[idx] if idx < len(mines_list) else 5\n",
    "\n",
    "        # Reconstruct game state\n",
    "        game = MinesweeperGame(rows=r_count, cols=c_count, num_mines=m_count, seed=seed)\n",
    "        for prev_action in move_history:\n",
    "            game.do_action(prev_action)\n",
    "\n",
    "        row, col = int(action[\"row\"]), int(action[\"col\"])\n",
    "        action_type = action[\"type\"]\n",
    "\n",
    "        # Out of bounds\n",
    "        if not (0 <= row < game.rows and 0 <= col < game.cols):\n",
    "            scores.append(-8.0)\n",
    "            continue\n",
    "\n",
    "        score = 0.0\n",
    "\n",
    "        if action_type == \"reveal\":\n",
    "            # Already revealed — wasted move\n",
    "            if (row, col) in game._revealed:\n",
    "                scores.append(-10.0)\n",
    "                continue\n",
    "            # Trying to reveal a flagged cell\n",
    "            if (row, col) in game._flagged:\n",
    "                scores.append(-10.0)\n",
    "                continue\n",
    "            # Hit a mine\n",
    "            if game._board[row][col] == -1:\n",
    "                scores.append(-25.0)\n",
    "                continue\n",
    "\n",
    "            # Safe reveal! Good.\n",
    "            score += 3.0\n",
    "\n",
    "            # Bonus: logically deducible safe cell (expert-level move)\n",
    "            if _is_logically_deducible_reveal(game, row, col):\n",
    "                score += 8.0\n",
    "            else:\n",
    "                # Still safe but a guess\n",
    "                score += 2.0\n",
    "\n",
    "            # Check if this move wins the game\n",
    "            game_copy = MinesweeperGame(rows=r_count, cols=c_count, num_mines=m_count, seed=seed)\n",
    "            for prev_action in move_history:\n",
    "                game_copy.do_action(prev_action)\n",
    "            if game_copy.do_action(action) == \"win\":\n",
    "                score += 50.0\n",
    "\n",
    "            # Bonus for revealing cells adjacent to numbers (informative)\n",
    "            adj_numbered = 0\n",
    "            for nr, nc in get_neighbors(row, col, game.rows, game.cols):\n",
    "                if (nr, nc) in game._revealed and game._board[nr][nc] > 0:\n",
    "                    adj_numbered += 1\n",
    "            score += adj_numbered * 1.0\n",
    "\n",
    "        elif action_type == \"flag\":\n",
    "            # Flagging already revealed cell\n",
    "            if (row, col) in game._revealed:\n",
    "                scores.append(-10.0)\n",
    "                continue\n",
    "            # Already flagged\n",
    "            if (row, col) in game._flagged:\n",
    "                scores.append(-15.0)\n",
    "                continue\n",
    "            # Too many flags\n",
    "            if len(game._flagged) + 1 > game.num_mines:\n",
    "                score -= 5.0\n",
    "\n",
    "            # Correct flag (is actually a mine)\n",
    "            if game._board[row][col] == -1:\n",
    "                score += 10.0\n",
    "                # Extra bonus if logically deducible\n",
    "                if _is_logically_deducible_flag(game, row, col):\n",
    "                    score += 5.0\n",
    "            else:\n",
    "                # Wrong flag\n",
    "                score -= 8.0\n",
    "\n",
    "            # Check win after flag\n",
    "            game_copy = MinesweeperGame(rows=r_count, cols=c_count, num_mines=m_count, seed=seed)\n",
    "            for prev_action in move_history:\n",
    "                game_copy.do_action(prev_action)\n",
    "            if game_copy.do_action(action) == \"win\":\n",
    "                score += 50.0\n",
    "\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def _is_logically_deducible_reveal(game, row, col):\n",
    "    \"\"\"Check if revealing this cell is logically safe (all adjacent mines flagged).\"\"\"\n",
    "    for dr in [-1, 0, 1]:\n",
    "        for dc in [-1, 0, 1]:\n",
    "            if dr == 0 and dc == 0:\n",
    "                continue\n",
    "            nr, nc = row + dr, col + dc\n",
    "            if not (0 <= nr < game.rows and 0 <= nc < game.cols):\n",
    "                continue\n",
    "            if (nr, nc) not in game._revealed:\n",
    "                continue\n",
    "            cell_val = game._board[nr][nc]\n",
    "            if cell_val <= 0:\n",
    "                continue\n",
    "            flagged_count = 0\n",
    "            hidden_count = 0\n",
    "            for dr2 in [-1, 0, 1]:\n",
    "                for dc2 in [-1, 0, 1]:\n",
    "                    if dr2 == 0 and dc2 == 0:\n",
    "                        continue\n",
    "                    nnr, nnc = nr + dr2, nc + dc2\n",
    "                    if not (0 <= nnr < game.rows and 0 <= nnc < game.cols):\n",
    "                        continue\n",
    "                    if (nnr, nnc) in game._flagged:\n",
    "                        flagged_count += 1\n",
    "                    elif (nnr, nnc) not in game._revealed:\n",
    "                        hidden_count += 1\n",
    "            if flagged_count == cell_val and hidden_count > 0:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def _is_logically_deducible_flag(game, row, col):\n",
    "    \"\"\"Check if flagging this cell is logically deducible (all hidden neighbors must be mines).\"\"\"\n",
    "    for dr in [-1, 0, 1]:\n",
    "        for dc in [-1, 0, 1]:\n",
    "            if dr == 0 and dc == 0:\n",
    "                continue\n",
    "            nr, nc = row + dr, col + dc\n",
    "            if not (0 <= nr < game.rows and 0 <= nc < game.cols):\n",
    "                continue\n",
    "            if (nr, nc) not in game._revealed:\n",
    "                continue\n",
    "            cell_val = game._board[nr][nc]\n",
    "            if cell_val <= 0:\n",
    "                continue\n",
    "            flagged_count = 0\n",
    "            hidden = []\n",
    "            for dr2 in [-1, 0, 1]:\n",
    "                for dc2 in [-1, 0, 1]:\n",
    "                    if dr2 == 0 and dc2 == 0:\n",
    "                        continue\n",
    "                    nnr, nnc = nr + dr2, nc + dc2\n",
    "                    if not (0 <= nnr < game.rows and 0 <= nnc < game.cols):\n",
    "                        continue\n",
    "                    if (nnr, nnc) in game._flagged:\n",
    "                        flagged_count += 1\n",
    "                    elif (nnr, nnc) not in game._revealed:\n",
    "                        hidden.append((nnr, nnc))\n",
    "            remaining = cell_val - flagged_count\n",
    "            if remaining == len(hidden) and (row, col) in hidden:\n",
    "                return True\n",
    "    return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1f9e927-82d6-4270-bfe2-73b836e073c1",
   "metadata": {},
   "outputs": [],
   "source": [
    " def generate_grpo_states(num_samples=3000, rng_seed=42):\n",
    "    \"\"\"\n",
    "    Generate game states for GRPO using the SOLVER to play moves.\n",
    "    This gives realistic mid-game states instead of random ones.\n",
    "    \"\"\"\n",
    "    from datasets import Dataset as HFDataset\n",
    "\n",
    "    random.seed(rng_seed)\n",
    "\n",
    "    board_configs = [\n",
    "        (5, 5, 4), (5, 5, 6),\n",
    "        (6, 6, 5), (6, 6, 7),\n",
    "        (7, 7, 8), (7, 7, 10),\n",
    "        (8, 8, 10), (8, 8, 13),\n",
    "    ]\n",
    "    weights = [1, 1, 4, 2, 1, 1, 1, 1]\n",
    "\n",
    "    dataset_items = []\n",
    "\n",
    "    while len(dataset_items) < num_samples:\n",
    "        config_idx = random.choices(range(len(board_configs)), weights=weights, k=1)[0]\n",
    "        rows, cols, num_mines = board_configs[config_idx]\n",
    "        seed = random.randint(0, 1_000_000)\n",
    "\n",
    "        game = MinesweeperGame(rows=rows, cols=cols, num_mines=num_mines, seed=seed)\n",
    "\n",
    "        # Use solver to play 0-15 moves (creates realistic game states)\n",
    "        num_moves = random.randint(0, 15)\n",
    "        move_history = []\n",
    "\n",
    "        for _ in range(num_moves):\n",
    "            if game.state() != \"ongoing\":\n",
    "                break\n",
    "            # Use our expert solver for realistic move sequences\n",
    "            action = solve_step(game)\n",
    "            if action is None:\n",
    "                break\n",
    "            result = game.do_action(action)\n",
    "            if result in (\"mine\", \"game_over\", \"invalid_format\"):\n",
    "                break\n",
    "            move_history.append(action)\n",
    "\n",
    "        if game.state() == \"ongoing\":\n",
    "            prompt_text = format_state_for_llm(game)\n",
    "            dataset_items.append({\n",
    "                \"prompt\": [\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\", \"content\": prompt_text},\n",
    "                ],\n",
    "                \"seed\": seed,\n",
    "                \"move_history\": json.dumps(move_history),\n",
    "                \"rows\": rows,\n",
    "                \"cols\": cols,\n",
    "                \"num_mines\": num_mines,\n",
    "            })\n",
    "\n",
    "    dataset = HFDataset.from_list(dataset_items)\n",
    "    print(f\"Created {len(dataset)} GRPO training states\")\n",
    "\n",
    "    size_counts = Counter(f\"{item['rows']}x{item['cols']}\" for item in dataset)\n",
    "    print(f\"Board sizes: {dict(size_counts)}\")\n",
    "\n",
    "    fresh_count = sum(1 for item in dataset if item[\"move_history\"] == \"[]\")\n",
    "    print(f\"Fresh games: {fresh_count} ({fresh_count/len(dataset)*100:.1f}%)\")\n",
    "    print(f\"Mid-game: {len(dataset)-fresh_count} ({(len(dataset)-fresh_count)/len(dataset)*100:.1f}%)\")\n",
    "\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb290757-733a-4c38-b207-b67235c88b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_grpo_trainer(model, tokenizer, dataset, max_seq_length=1024):\n",
    "    \"\"\"Configure and return the GRPO trainer.\"\"\"\n",
    "    from trl import GRPOConfig, GRPOTrainer\n",
    "    from transformers import TrainerCallback\n",
    "\n",
    "    max_prompt_length = 700\n",
    "    max_completion_length = max_seq_length - max_prompt_length\n",
    "\n",
    "    # Eval callback\n",
    "    class MinesweeperEvalCallback(TrainerCallback):\n",
    "        def __init__(self, eval_every_steps=50, num_games=10):\n",
    "            self.eval_every_steps = eval_every_steps\n",
    "            self.num_games = num_games\n",
    "\n",
    "        def on_step_end(self, args, state, control, model=None, processing_class=None, **kwargs):\n",
    "            if state.global_step % self.eval_every_steps != 0:\n",
    "                return\n",
    "            tok = processing_class\n",
    "            if tok is None or model is None:\n",
    "                return\n",
    "            was_training = model.training\n",
    "            model.eval()\n",
    "            wins = 0\n",
    "            total_moves = 0\n",
    "            for i in range(self.num_games):\n",
    "                game = MinesweeperGame(rows=6, cols=6, num_mines=5, seed=10000 + i)\n",
    "                moves = 0\n",
    "                invalid_streak = 0\n",
    "                while game.state() == \"ongoing\" and moves < 50:\n",
    "                    prompt = format_state_for_llm(game)\n",
    "                    text = tok.apply_chat_template(\n",
    "                        [{\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                         {\"role\": \"user\", \"content\": prompt}],\n",
    "                        tokenize=False, add_generation_prompt=True,\n",
    "                    )\n",
    "                    inputs = tok(text, return_tensors=\"pt\", truncation=True,\n",
    "                                 max_length=max_seq_length).to(model.device)\n",
    "                    output = model.generate(\n",
    "                        **inputs,\n",
    "                        temperature=0.3, max_new_tokens=64, do_sample=True,\n",
    "                    )\n",
    "                    gen_tokens = output[0][inputs[\"input_ids\"].shape[1]:]\n",
    "                    response = tok.decode(gen_tokens, skip_special_tokens=True).strip()\n",
    "                    action = parse_llm_action(response)\n",
    "                    if action is None:\n",
    "                        break\n",
    "                    result = game.do_action(action)\n",
    "                    if result in (\"mine\", \"game_over\"):\n",
    "                        break                          # Fatal — game ends\n",
    "                    if result in (\"already_revealed\", \"flagged_cell\", \"invalid_flag\",\n",
    "                                  \"out_of_bounds\", \"invalid_format\"):\n",
    "                        invalid_streak += 1\n",
    "                        if invalid_streak >= 3:\n",
    "                            break                      # Too many invalid in a row\n",
    "                        continue                       # Skip and retry\n",
    "                    invalid_streak = 0                 # Reset on valid move\n",
    "                    moves += 1\n",
    "                total_moves += moves\n",
    "                if game.state() == \"success\":\n",
    "                    wins += 1\n",
    "            avg_moves = total_moves / self.num_games\n",
    "            print(f\"\\n[Eval @ step {state.global_step}] Win rate: {wins}/{self.num_games} \"\n",
    "                  f\"({wins/self.num_games*100:.0f}%) | Avg moves: {avg_moves:.1f}\\n\")\n",
    "            if was_training:\n",
    "                model.train()\n",
    "\n",
    "    eval_callback = MinesweeperEvalCallback(eval_every_steps=50, num_games=10)\n",
    "\n",
    "    # GRPO Config — v3 tuned\n",
    "    grpo_config = GRPOConfig(\n",
    "        temperature=2.0,                # Higher = more diverse (anti mode collapse)\n",
    "        learning_rate=3e-5,             # Slower — refining, not relearning\n",
    "        weight_decay=0.01,\n",
    "        warmup_ratio=0.1,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        optim=\"adamw_8bit\",\n",
    "        logging_steps=1,\n",
    "        per_device_train_batch_size=6,\n",
    "        gradient_accumulation_steps=4,\n",
    "        num_generations=6,\n",
    "        max_prompt_length=max_prompt_length,\n",
    "        max_completion_length=max_completion_length,\n",
    "        max_steps=200,                  # Stop before mode collapse\n",
    "        save_steps=50,                  # Save more often\n",
    "        save_total_limit=4,\n",
    "        report_to=\"none\",\n",
    "        output_dir=\"minesweeper_grpo_v3_outputs\",\n",
    "    )\n",
    "\n",
    "    trainer = GRPOTrainer(\n",
    "        model=model,\n",
    "        processing_class=tokenizer,\n",
    "        train_dataset=dataset,\n",
    "        reward_funcs=[valid_json_reward, gameplay_reward],\n",
    "        args=grpo_config,\n",
    "        callbacks=[eval_callback],\n",
    "    )\n",
    "\n",
    "    print(\"GRPO Trainer ready!\")\n",
    "    print(f\"  Max steps: {grpo_config.max_steps}\")\n",
    "    print(f\"  Generations per state: {grpo_config.num_generations}\")\n",
    "    print(f\"  Temperature: {grpo_config.temperature}\")\n",
    "    print(f\"  Learning rate: {grpo_config.learning_rate}\")\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5dfa91c4-a738-45d7-b551-2077fab26a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_grpo(trainer):\n",
    "    \"\"\"Run GRPO training.\"\"\"\n",
    "    print(\"Starting GRPO training on SFT model...\")\n",
    "    trainer.train()\n",
    "    print(\"GRPO Training complete!\")\n",
    "    return trainer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6978920c-32b0-41be-bd14-3cc059b7140f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: AMD currently is not stable with 4bit bitsandbytes. Disabling for now.\n",
      "==((====))==  Unsloth 2025.10.6: Fast Llama patching. Transformers: 4.56.2. vLLM: 0.11.1rc2.dev161+g8a297115e.rocm700.\n",
      "   \\\\   /|    . Num GPUs = 1. Max memory: 255.688 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+gitb2fb688. ROCm Toolkit: 7.0.51831-a3e329ad8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8760594352241fd9ade960c0066e71a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munsloth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastLanguageModel\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m model_ckpt, tokenizer_ckpt = \u001b[43mFastLanguageModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mminesweeper_sft_outputs/checkpoint-1000\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m FastLanguageModel.for_inference(model_ckpt)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEvaluating checkpoint-200...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/unsloth/models/loader.py:471\u001b[39m, in \u001b[36mFastLanguageModel.from_pretrained\u001b[39m\u001b[34m(model_name, max_seq_length, dtype, load_in_4bit, load_in_8bit, load_in_16bit, full_finetuning, token, device_map, rope_scaling, fix_tokenizer, trust_remote_code, use_gradient_checkpointing, resize_model_vocab, revision, use_exact_model_name, offload_embedding, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, qat_scheme, *args, **kwargs)\u001b[39m\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fast_inference:\n\u001b[32m    469\u001b[39m     fast_inference, model_name = fast_inference_setup(model_name, model_config)\n\u001b[32m--> \u001b[39m\u001b[32m471\u001b[39m model, tokenizer = \u001b[43mdispatch_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m    \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m             \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_get_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m             \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_patcher\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdispatch_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m    \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m          \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_peft\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfast_inference\u001b[49m\u001b[43m    \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfast_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgpu_memory_utilization\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu_memory_utilization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfloat8_kv_cache\u001b[49m\u001b[43m   \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfloat8_kv_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_lora_rank\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_lora_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resize_model_vocab \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    495\u001b[39m     model.resize_token_embeddings(resize_model_vocab)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/unsloth/models/llama.py:2031\u001b[39m, in \u001b[36mFastLlamaModel.from_pretrained\u001b[39m\u001b[34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, model_patcher, tokenizer_name, trust_remote_code, revision, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, unsloth_vllm_standby, num_labels, qat_scheme, **kwargs)\u001b[39m\n\u001b[32m   2018\u001b[39m     model = AutoModelForSequenceClassification.from_pretrained(\n\u001b[32m   2019\u001b[39m         model_name,\n\u001b[32m   2020\u001b[39m         device_map              = device_map,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2028\u001b[39m         **kwargs,\n\u001b[32m   2029\u001b[39m     )\n\u001b[32m   2030\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fast_inference:\n\u001b[32m-> \u001b[39m\u001b[32m2031\u001b[39m     model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2032\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2033\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m              \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2034\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# torch_dtype             = dtype, # transformers changed torch_dtype to dtype\u001b[39;49;00m\n\u001b[32m   2035\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# quantization_config     = bnb_config,\u001b[39;49;00m\n\u001b[32m   2036\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m                   \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2037\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_position_embeddings\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_position_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2038\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m       \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2039\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_implementation\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meager\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2040\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2041\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2042\u001b[39m     model.fast_generate = model.generate\n\u001b[32m   2043\u001b[39m     model.fast_generate_batches = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py:604\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    602\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    603\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    608\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    609\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    610\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py:288\u001b[39m, in \u001b[36mrestore_default_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    286\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    290\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py:5179\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   5169\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5170\u001b[39m         torch.set_default_dtype(dtype_orig)\n\u001b[32m   5172\u001b[39m     (\n\u001b[32m   5173\u001b[39m         model,\n\u001b[32m   5174\u001b[39m         missing_keys,\n\u001b[32m   5175\u001b[39m         unexpected_keys,\n\u001b[32m   5176\u001b[39m         mismatched_keys,\n\u001b[32m   5177\u001b[39m         offload_index,\n\u001b[32m   5178\u001b[39m         error_msgs,\n\u001b[32m-> \u001b[39m\u001b[32m5179\u001b[39m     ) = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5180\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5183\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5184\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5185\u001b[39m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5186\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5187\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5188\u001b[39m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5189\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5190\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5191\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5192\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5195\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5196\u001b[39m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[32m   5197\u001b[39m model.tie_weights()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py:5642\u001b[39m, in \u001b[36mPreTrainedModel._load_pretrained_model\u001b[39m\u001b[34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[39m\n\u001b[32m   5639\u001b[39m         args_list = logging.tqdm(args_list, desc=\u001b[33m\"\u001b[39m\u001b[33mLoading checkpoint shards\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   5641\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m args_list:\n\u001b[32m-> \u001b[39m\u001b[32m5642\u001b[39m         _error_msgs, disk_offload_index, cpu_offload_index = \u001b[43mload_shard_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5643\u001b[39m         error_msgs += _error_msgs\n\u001b[32m   5645\u001b[39m \u001b[38;5;66;03m# Adjust offloaded weights name and save if needed\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py:946\u001b[39m, in \u001b[36mload_shard_file\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m    944\u001b[39m \u001b[38;5;66;03m# Skip it with fsdp on ranks other than 0\u001b[39;00m\n\u001b[32m    945\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_fsdp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_quantized):\n\u001b[32m--> \u001b[39m\u001b[32m946\u001b[39m     disk_offload_index, cpu_offload_index = \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreverse_key_renaming_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcpu_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_offloaded_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m        \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m error_msgs, disk_offload_index, cpu_offload_index\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py:815\u001b[39m, in \u001b[36m_load_state_dict_into_meta_model\u001b[39m\u001b[34m(model, state_dict, shard_file, expected_keys, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, cpu_offload_folder, cpu_offload_index, hf_quantizer, is_safetensors, keep_in_fp32_regex, unexpected_keys, device_mesh)\u001b[39m\n\u001b[32m    813\u001b[39m param = param[...]\n\u001b[32m    814\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m casting_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m815\u001b[39m     param = \u001b[43mparam\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasting_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    816\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m to_contiguous:\n\u001b[32m    817\u001b[39m     param = param.contiguous()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Load checkpoint-200 and evaluate\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "model_ckpt, tokenizer_ckpt = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"minesweeper_sft_outputs/checkpoint-1000\",\n",
    "    load_in_4bit=True,\n",
    "    max_seq_length=1024,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "FastLanguageModel.for_inference(model_ckpt)\n",
    "\n",
    "print(\"\\nEvaluating checkpoint-200...\")\n",
    "wins = 0\n",
    "total_moves = 0\n",
    "num_games = 20\n",
    "\n",
    "for i in range(num_games):\n",
    "    game = MinesweeperGame(rows=6, cols=6, num_mines=5, seed=50000 + i)\n",
    "    moves = 0\n",
    "    while game.state() == \"ongoing\" and moves < 100:\n",
    "        prompt = format_state_for_llm(game)\n",
    "        text = tokenizer_ckpt.apply_chat_template(\n",
    "            [{\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "             {\"role\": \"user\", \"content\": prompt}],\n",
    "            tokenize=False, add_generation_prompt=True,\n",
    "        )\n",
    "        inputs = tokenizer_ckpt(text, return_tensors=\"pt\", truncation=True,\n",
    "                                max_length=1024).to(model_ckpt.device)\n",
    "        output = model_ckpt.generate(\n",
    "            **inputs,\n",
    "            temperature=0.3, max_new_tokens=64, do_sample=True,\n",
    "        )\n",
    "        gen_tokens = output[0][inputs[\"input_ids\"].shape[1]:]\n",
    "        response = tokenizer_ckpt.decode(gen_tokens, skip_special_tokens=True).strip()\n",
    "        action = parse_llm_action(response)\n",
    "        if action is None:\n",
    "            print(f\"  Game {i+1}: PARSE FAIL after {moves} moves\")\n",
    "            break\n",
    "        result = game.do_action(action)\n",
    "        if result in (\"mine\", \"game_over\", \"invalid_format\", \"already_revealed\",\n",
    "                      \"out_of_bounds\", \"flagged_cell\", \"invalid_flag\"):\n",
    "            break\n",
    "        moves += 1\n",
    "    total_moves += moves\n",
    "    status = \"WIN\" if game.state() == \"success\" else \"LOSS\"\n",
    "    if game.state() == \"success\":\n",
    "        wins += 1\n",
    "    print(f\"  Game {i+1}: {status} after {moves} moves\")\n",
    "\n",
    "avg_moves = total_moves / num_games\n",
    "print(f\"\\nCheckpoint-200 Results:\")\n",
    "print(f\"  Win rate: {wins}/{num_games} ({wins/num_games*100:.1f}%)\")\n",
    "print(f\"  Avg moves survived: {avg_moves:.1f}\")\n",
    "print(f\"  (SFT baseline: 2/20 wins, 2.9 avg moves)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9818c66-6037-4ad9-b7d1-1afa194b3b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_grpo_model(model, tokenizer):\n",
    "    \"\"\"Save the GRPO-refined model.\"\"\"\n",
    "    model.save_pretrained(\"my_minesweeper_model_grpo\")\n",
    "    tokenizer.save_pretrained(\"my_minesweeper_model_grpo\")\n",
    "    print(\"GRPO model saved to: my_minesweeper_model_grpo/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7fc9353-44cd-4ce8-b665-040347938cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: AMD currently is not stable with 4bit bitsandbytes. Disabling for now.\n",
      "==((====))==  Unsloth 2025.10.6: Fast Llama patching. Transformers: 4.56.2. vLLM: 0.11.1rc2.dev161+g8a297115e.rocm700.\n",
      "   \\\\   /|    . Num GPUs = 1. Max memory: 255.688 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+gitb2fb688. ROCm Toolkit: 7.0.51831-a3e329ad8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e6f81e40ff440eaf5d79c98bd6698d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Already have LoRA adapters! We shall skip this step.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model device: cuda:0\n",
      "SFT model loaded with fresh LoRA for GRPO!\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer, max_seq_length = load_sft_model_for_grpo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1091c20e-90d2-4cd7-9d38-fd60e0555dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 3000 GRPO training states\n",
      "Board sizes: {'6x6': 1547, '5x5': 369, '7x7': 510, '8x8': 574}\n",
      "Fresh games: 315 (10.5%)\n",
      "Mid-game: 2685 (89.5%)\n"
     ]
    }
   ],
   "source": [
    "grpo_dataset = generate_grpo_states(num_samples=3000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7fe35515-dc01-43ba-b1f2-1c071812797c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRPO Trainer ready!\n",
      "  Max steps: 200\n",
      "  Generations per state: 6\n",
      "  Temperature: 4.0\n",
      "  Learning rate: 2e-06\n"
     ]
    }
   ],
   "source": [
    "trainer = setup_grpo_trainer(model, tokenizer, grpo_dataset, max_seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0ab3aee-4555-47b7-8e32-b79514359c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GRPO training on SFT model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 3,000 | Num Epochs = 1 | Total steps = 200\n",
      "O^O/ \\_/ \\    Batch size per device = 6 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (6 x 4 x 1) = 24\n",
      " \"-____-\"     Trainable parameters = 41,943,040 of 8,072,204,288 (0.52% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  5/200 00:38 < 41:46, 0.08 it/s, Epoch 0.01/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>reward</th>\n",
       "      <th>reward_std</th>\n",
       "      <th>completions / mean_length</th>\n",
       "      <th>completions / min_length</th>\n",
       "      <th>completions / max_length</th>\n",
       "      <th>completions / clipped_ratio</th>\n",
       "      <th>completions / mean_terminated_length</th>\n",
       "      <th>completions / min_terminated_length</th>\n",
       "      <th>completions / max_terminated_length</th>\n",
       "      <th>sampling / sampling_logp_difference / mean</th>\n",
       "      <th>sampling / sampling_logp_difference / max</th>\n",
       "      <th>sampling / importance_sampling_ratio / min</th>\n",
       "      <th>sampling / importance_sampling_ratio / mean</th>\n",
       "      <th>sampling / importance_sampling_ratio / max</th>\n",
       "      <th>kl</th>\n",
       "      <th>rewards / valid_json_reward / mean</th>\n",
       "      <th>rewards / valid_json_reward / std</th>\n",
       "      <th>rewards / gameplay_reward / mean</th>\n",
       "      <th>rewards / gameplay_reward / std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002505</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_grpo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mtrain_grpo\u001b[39m\u001b[34m(trainer)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Run GRPO training.\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting GRPO training on SFT model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGRPO Training complete!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/unsloth_compiled_cache/UnslothGRPOTrainer.py:53\u001b[39m, in \u001b[36mprepare_for_training_mode.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model, \u001b[33m\"\u001b[39m\u001b[33mfor_training\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     52\u001b[39m     \u001b[38;5;28mself\u001b[39m.model.for_training()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m output = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Return inference mode\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model, \u001b[33m\"\u001b[39m\u001b[33mfor_inference\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py:2328\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2326\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2327\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2333\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:325\u001b[39m, in \u001b[36m_fast_inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:34\u001b[39m, in \u001b[36m_unsloth_training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/trl/extras/profiling.py:98\u001b[39m, in \u001b[36mprofiling_decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m profiling_context(\u001b[38;5;28mself\u001b[39m, func.\u001b[34m__name__\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/unsloth_compiled_cache/UnslothGRPOTrainer.py:2048\u001b[39m, in \u001b[36m_UnslothGRPOTrainer._prepare_inputs\u001b[39m\u001b[34m(self, generation_batch)\u001b[39m\n\u001b[32m   2045\u001b[39m generate_every = \u001b[38;5;28mself\u001b[39m.args.steps_per_generation * \u001b[38;5;28mself\u001b[39m.num_iterations\n\u001b[32m   2046\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._step % generate_every == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffered_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2047\u001b[39m     \u001b[38;5;66;03m# self._buffered_inputs=None can occur when resuming from a checkpoint\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2048\u001b[39m     generation_batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_and_score_completions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeneration_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2049\u001b[39m     generation_batch = split_pixel_values_by_grid(generation_batch)\n\u001b[32m   2051\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m: generation_batch = shuffle_sequence_dict(generation_batch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/unsloth_compiled_cache/UnslothGRPOTrainer.py:2380\u001b[39m, in \u001b[36m_UnslothGRPOTrainer._generate_and_score_completions\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m   2371\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m (\n\u001b[32m   2372\u001b[39m     profiling_context(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtransformers.generate\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   2373\u001b[39m     unwrap_model_for_generation(\n\u001b[32m   (...)\u001b[39m\u001b[32m   2377\u001b[39m     FSDP.summon_full_params(\u001b[38;5;28mself\u001b[39m.model_wrapped, recurse=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_fsdp_enabled \u001b[38;5;28;01melse\u001b[39;00m nullcontext(),\n\u001b[32m   2378\u001b[39m ):\n\u001b[32m   2379\u001b[39m     prompt_inputs[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m], prompt_inputs[\u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m] = prompt_ids, prompt_mask\n\u001b[32m-> \u001b[39m\u001b[32m2380\u001b[39m     prompt_completion_ids = \u001b[43munwrapped_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2381\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mprompt_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_compile\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m   2382\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2383\u001b[39m \u001b[38;5;66;03m# Compute prompt length and extract completion ids\u001b[39;00m\n\u001b[32m   2384\u001b[39m prompt_length = prompt_ids.size(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/unsloth/models/rl.py:71\u001b[39m, in \u001b[36mPatchRL.<locals>.unsloth_unwrap_model_for_generation.<locals>.generate_with_clone\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_with_clone\u001b[39m(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     out = \u001b[43moriginal_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, torch.Tensor):\n\u001b[32m     73\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m out.clone()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/peft/peft_model.py:1973\u001b[39m, in \u001b[36mPeftModelForCausalLM.generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1971\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_peft_forward_hooks(*args, **kwargs):\n\u001b[32m   1972\u001b[39m         kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.special_peft_forward_args}\n\u001b[32m-> \u001b[39m\u001b[32m1973\u001b[39m         outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1974\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1975\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.base_model.generate(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/unsloth/models/llama.py:1775\u001b[39m, in \u001b[36munsloth_fast_generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m \u001b[38;5;66;03m# Mixed precision autocast\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode(), torch.autocast(device_type = DEVICE_TYPE_TORCH, dtype = dtype):\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_old_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1776\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1778\u001b[39m \u001b[38;5;66;03m# Return accelerate back\u001b[39;00m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# if accelerate_new_send_to_device is not None:\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m#     accelerate.utils.operations.send_to_device = accelerate_old_send_to_device\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# pass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py:2539\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2528\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m GenerationMixin.generate(\n\u001b[32m   2529\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2530\u001b[39m         inputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2534\u001b[39m         **kwargs,\n\u001b[32m   2535\u001b[39m     )\n\u001b[32m   2537\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.SAMPLE, GenerationMode.GREEDY_SEARCH):\n\u001b[32m   2538\u001b[39m     \u001b[38;5;66;03m# 11. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2539\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2540\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2541\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2542\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2543\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2544\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2545\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2546\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2547\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2549\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2550\u001b[39m     \u001b[38;5;66;03m# 11. run beam sample\u001b[39;00m\n\u001b[32m   2551\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._beam_search(\n\u001b[32m   2552\u001b[39m         input_ids,\n\u001b[32m   2553\u001b[39m         logits_processor=prepared_logits_processor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2557\u001b[39m         **model_kwargs,\n\u001b[32m   2558\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py:2870\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   2868\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   2869\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2870\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2872\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   2873\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   2874\u001b[39m     outputs,\n\u001b[32m   2875\u001b[39m     model_kwargs,\n\u001b[32m   2876\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2877\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/unsloth/models/llama.py:1140\u001b[39m, in \u001b[36mCausalLM_fast_forward.<locals>._CausalLM_fast_forward\u001b[39m\u001b[34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[39m\n\u001b[32m   1122\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_CausalLM_fast_forward\u001b[39m(\n\u001b[32m   1123\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1124\u001b[39m     input_ids: torch.LongTensor = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1137\u001b[39m     *args, **kwargs,\n\u001b[32m   1138\u001b[39m ) -> Union[Tuple, CausalLMOutputWithPast]:\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1140\u001b[39m         outputs = \u001b[43mfast_forward_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1142\u001b[39m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1143\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1144\u001b[39m \u001b[43m            \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1145\u001b[39m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1146\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1147\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1148\u001b[39m         causal_mask = xformers.attn_bias.LowerTriangularMask() \u001b[38;5;28;01mif\u001b[39;00m HAS_XFORMERS \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/unsloth/models/llama.py:1073\u001b[39m, in \u001b[36m_LlamaModel_fast_forward_inference.<locals>.LlamaModel_fast_forward_inference_custom\u001b[39m\u001b[34m(self, input_ids, past_key_values, position_ids, attention_mask)\u001b[39m\n\u001b[32m   1065\u001b[39m residual.copy_(X) \u001b[38;5;66;03m# residual = X\u001b[39;00m\n\u001b[32m   1066\u001b[39m X = fast_rms_layernorm_inference(\n\u001b[32m   1067\u001b[39m     decoder_layer.input_layernorm,\n\u001b[32m   1068\u001b[39m     X,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1071\u001b[39m     variance = variance,\n\u001b[32m   1072\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1073\u001b[39m X, present_key_value = \u001b[43mattention_fast_forward_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1078\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdo_prefill\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpaged_attention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1080\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1081\u001b[39m X += residual\n\u001b[32m   1083\u001b[39m residual.copy_(X) \u001b[38;5;66;03m# residual = X\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/unsloth/models/llama.py:304\u001b[39m, in \u001b[36mLlamaAttention_fast_forward_inference\u001b[39m\u001b[34m(self, hidden_states, past_key_value, position_ids, do_prefill, attention_mask)\u001b[39m\n\u001b[32m    302\u001b[39m RH_Q[:,:,:,:h].neg_() \u001b[38;5;66;03m# torch.neg(RH_Q[:,:,:,:h], out = RH_Q[:,:,:,:h])\u001b[39;00m\n\u001b[32m    303\u001b[39m Qn *= cos\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m \u001b[43mQn\u001b[49m\u001b[43m.\u001b[49m\u001b[43maddcmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRH_Q\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    306\u001b[39m RH_K = RH_Q[:,:n_kv_heads,:,:] \u001b[38;5;66;03m# torch.empty((n_kv_heads, 1, head_dim), dtype = dtype, device = \"cuda:0\")\u001b[39;00m\n\u001b[32m    307\u001b[39m RH_K[:,:,:,:h] = Kn[:,:,:,h:]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_grpo(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba52b5fd-89d2-4745-b744-2305c056df3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_grpo_model(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7deecc-80c8-45d4-b4b7-90f2d596caec",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_grpo_model(model, tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
